{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserting Data Without Duplicates\n",
    "\n",
    "Here we test inserting data without duplicates. Afterwards we'll test for missing data inside of the databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/skywalker/PycharmProjects/jamboree/test/notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/skywalker/PycharmProjects/jamboree\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jamboree import Jamboree\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pandas_datareader.data as web\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maya import MayaDT\n",
    "import maya\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import orjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to create library with name: events\n"
     ]
    },
    {
     "ename": "LibraryNotFoundException",
     "evalue": "Library events was not correctly initialized in <Arctic at 0x7efbaa926128, connected to MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True, maxpoolsize=4, sockettimeoutms=600000, connecttimeoutms=2000, serverselectiontimeoutms=30000)>.\nReason: ServerSelectionTimeoutError('localhost:27017: [Errno 111] Connection refused',))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLibraryNotFoundException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-00a3bcc8c141>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjam_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJamboree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/jamboree/jamboree/base/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mongodb_host, redis_host, redis_port)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmongodb_host\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"localhost\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredis_host\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"localhost\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredis_port\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6379\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mredis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRedis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredis_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mredis_port\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmongodb_host\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'events'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'events'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThreadPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/arctic/arctic.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mArcticException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unrecognised library specification - use [libraryName]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/arctic/arctic.py\u001b[0m in \u001b[0;36mget_library\u001b[0;34m(self, library)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             raise LibraryNotFoundException(\"Library %s was not correctly initialized in %s.\\nReason: %r)\" %\n\u001b[0;32m--> 360\u001b[0;31m                                            (library, self, error))\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlib_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             raise LibraryNotFoundException(\"Library %s was not correctly initialized in %s.\" %\n",
      "\u001b[0;31mLibraryNotFoundException\u001b[0m: Library events was not correctly initialized in <Arctic at 0x7efbaa926128, connected to MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True, maxpoolsize=4, sockettimeoutms=600000, connecttimeoutms=2000, serverselectiontimeoutms=30000)>.\nReason: ServerSelectionTimeoutError('localhost:27017: [Errno 111] Connection refused',))"
     ]
    }
   ],
   "source": [
    "jam_session = Jamboree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime(1986, 3, 14)\n",
    "end = datetime.datetime(2020, 1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_df = web.DataReader(\"AAPL\", 'yahoo', start, end)\n",
    "msft_df = web.DataReader(\"MSFT\", 'yahoo', start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year_month_day(time:MayaDT):\n",
    "    print(f\"{time.day}-{time.month}-{time.year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_dt(df):\n",
    "    indexes = df.index\n",
    "    indexes = [maya.MayaDT.from_datetime(index.to_pydatetime()) for index in indexes]\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_records(df):\n",
    "    return df.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_record(record):\n",
    "    closing_record = {}\n",
    "    if \"Close\" in record:\n",
    "        closing_record['close'] = record[\"Close\"]\n",
    "    if \"Open\" in record:\n",
    "        closing_record['open'] = record[\"Open\"]\n",
    "    if \"Low\" in record:\n",
    "        closing_record['low'] = record[\"Low\"]\n",
    "    if \"High\" in record:\n",
    "        closing_record['high'] = record[\"High\"]\n",
    "    if \"Volume\" in record:\n",
    "        closing_record['volume'] = record[\"Volume\"]\n",
    "    if \"Adj Close\" in record:\n",
    "        closing_record['adj_close'] = record[\"\"]\n",
    "    return closing_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_outputs(records:List[Dict[str, Any]]):\n",
    "    if len(records) == 0:\n",
    "        return []\n",
    "    _records = [standardize_record(rec) for rec in records]\n",
    "    return _records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time(records, times):\n",
    "    if len(records) == 0 or (len(records) != len(times)):\n",
    "        return []\n",
    "    \n",
    "    _records = []\n",
    "    for index, rec in enumerate(records):\n",
    "        rec['time'] = times[index]._epoch\n",
    "        _records.append(rec)\n",
    "    return _records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teardown(df):\n",
    "    \"\"\"Breaks the dataframe into a bunch of dictionaries\"\"\"\n",
    "    indexes = get_time_dt(df)\n",
    "    records = df_records(df)\n",
    "    standardized = standardize_outputs(records)\n",
    "#     print(standardized)\n",
    "    with_time = add_time(standardized, indexes)\n",
    "    return with_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_time = teardown(apple_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip(n=0.05):\n",
    "    if random.uniform(0, 1) < n:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_duplicates(frame_dict_list:List[Dict]):\n",
    "    if len(frame_dict_list) == 0:\n",
    "        return []\n",
    "    \n",
    "    final_list = []\n",
    "    for item in frame_dict_list:\n",
    "        final_list.append(item)\n",
    "        if flip(0.1):\n",
    "            final_list.append(item)\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_200 = dt_time[-200:]\n",
    "last_300 = dt_time[-300:]\n",
    "last_200_dups = create_duplicates(last_200)\n",
    "last_300_dups = create_duplicates(last_300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsert_data_one = jam_session.bulk_upsert_redis({\"type\": \"sample_save\", \"asset\": \"AAPL\", \"label\": \"duplication\"}, last_200)\n",
    "upsert_data_two = jam_session.bulk_upsert_redis({\"type\": \"sample_save\", \"asset\": \"AAPL\", \"label\": \"duplication\"}, last_300)\n",
    "upsert_data_one_dups = jam_session.bulk_upsert_redis({\"type\": \"sample_save\", \"asset\": \"AAPL\", \"label\": \"duplication\"}, last_200_dups)\n",
    "upsert_data_two_dups = jam_session.bulk_upsert_redis({\"type\": \"sample_save\", \"asset\": \"AAPL\", \"label\": \"duplication\"}, last_300_dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_hash = upsert_data_one.get(\"hash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up1 = upsert_data_one.get('updated', [])\n",
    "up2 = upsert_data_two.get('updated', [])\n",
    "up3 = upsert_data_one_dups.get('updated', [])\n",
    "up4 = upsert_data_two_dups.get('updated', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr1 = [orjson.dumps(x) for x in up1]\n",
    "cr2 = [orjson.dumps(x) for x in up2]\n",
    "cr3 = [orjson.dumps(x) for x in up3]\n",
    "cr4 = [orjson.dumps(x) for x in up4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = set(cr1)\n",
    "set2 = set(cr2)\n",
    "set3 = set(cr3)\n",
    "set4 = set(cr4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set1))\n",
    "print(len(set2))\n",
    "print(len(set3))\n",
    "print(len(set4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jam_session.redis.sadd(set_key, *set(cr3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_list(serialized_list:list):\n",
    "    if len(serialized_list) == 0:\n",
    "        return []\n",
    "    \n",
    "    return [orjson.loads(x) for x in serialized_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_timestamp(item):\n",
    "    item['timestamp'] = maya.now()._epoch\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_addable_items(set_key, added_set):\n",
    "    existing = set(jam_session.redis.smembers(set_key))\n",
    "    addable_items = set(set2 - existing)\n",
    "    if len(addable_items) == 0:\n",
    "        return []\n",
    "    listified = list(addable_items)\n",
    "    deku = deserialize_list(listified)\n",
    "    timestamped = [add_timestamp(x) for x in deku]\n",
    "    return timestamped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated_set = set(serialized_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_addable_items(set_key, set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jam_session.redis.smembers(set_key, 0, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(retrieved - updated_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(retrieved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(updated_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}