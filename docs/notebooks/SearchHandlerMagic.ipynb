{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Magic Function Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desired Save Usage\n",
    "\n",
    "```py\n",
    "sand = SearchHandler()\n",
    "sand.processor = processor\n",
    "sand['description'] = \"Description goes here\"\n",
    "sand['name'] = \"Name goes here\"\n",
    "sand['category'] = \"Category goes here\"\n",
    "sand['derp'] = ['list', 'of', 'tags']\n",
    "\n",
    "sand.save() # this would automatically save a record\n",
    "```\n",
    "\n",
    "## Here's How Updates Would Function\n",
    "\n",
    "```py\n",
    "sand = SearchHandler()\n",
    "sand.processor = processor\n",
    "sand['description'] = \"Description goes here\"\n",
    "sand['name'] = \"Name goes here\"\n",
    "sand['category'] = \"Category goes here\"\n",
    "sand['derp'] = ['list', 'of', 'tags']\n",
    "sand.find() # This would be the query function. Query is too generic. We're gonna replace mongodb's formatting.\n",
    "sand.replacement['description'] = \"Description goes heresss\"\n",
    "sand.update() # this would automatically replace the top record we have from the find function.\n",
    "\n",
    "# if we have a set of document ids we can iterate through them and update the status by finding\n",
    "doc_ids = [uuid.uuid4().hex for _ in range(ids)]\n",
    "sand = SearchHandler()\n",
    "sand.processor = processor\n",
    "sand.replacement['status'] = \"FILLED\"\n",
    "for _id in doc_ids:\n",
    "    sand.doc_id = _id\n",
    "    sand.update() # it would find and update the exact field for the given id.\n",
    "```\n",
    "\n",
    "## Create Subcategories\n",
    "\n",
    "For things like metadata we would create a massive subcategory field that we could query through.\n",
    "\n",
    "\n",
    "```py\n",
    "sand['subcategories'] = {\n",
    "    \"country\": \"US\",\n",
    "    \"market\": \"crypto\",\n",
    "    \"exchange\": \"coinbase\",\n",
    "    \"loc\": {\n",
    "        \"type\": \"GEO\"\n",
    "        \"is_filter\": False,\n",
    "        \"values\": {\n",
    "            \"long\": 33,\n",
    "            \"lat\": -10,\n",
    "            \"distance\": 1,\n",
    "            \"metric\": \"km\"\n",
    "        }\n",
    "        \n",
    "    }\n",
    "}\n",
    "\n",
    "# would turn into:\n",
    "\n",
    "sub_index = f'{requirements_hash}:subcategories'\n",
    "```\n",
    "\n",
    "It would go through and find all of the field types. If it's a dictionary, we'd look through to find a `type` key. If there's not a `type` key, we'd skip it. We'd then add an extra value where we can relate the subcategory information directly to the main key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jamboree.utils.support.search.validation import is_nested, is_gen_type, name_match, is_generic, is_geo, to_str, to_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jamboree.utils.core import consistent_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseSearchHandlerSupport(object):\n",
    "    def __init__(self):\n",
    "        self._requirements_str = {\n",
    "            \n",
    "        }\n",
    "        self._subkey_names = set()\n",
    "        self._indexable = set()\n",
    "        self._index_key:str = \"\"\n",
    "        self._sub_fields = {}\n",
    "    \n",
    "    @property\n",
    "    def indexable(self):\n",
    "        return list(self._indexable)\n",
    "    \n",
    "    @property\n",
    "    def subnames(self):\n",
    "        return self._subkey_names\n",
    "    @property\n",
    "    def index(self):\n",
    "        \"\"\"Index key for the requirements\"\"\"\n",
    "        return self._index_key\n",
    "    \n",
    "    @property\n",
    "    def subfields(self):\n",
    "        return self._sub_fields\n",
    "    \n",
    "    def process_subfields(self):\n",
    "        for key in self.subnames:\n",
    "            self._sub_fields[key] = f\"{self.index}:{key}\"\n",
    "    \n",
    "    def process_requirements(self, _requirements:dict):\n",
    "        \"\"\"\n",
    "            Process the required fields. That includes:\n",
    "            \n",
    "            1. Creating a requirements string. That's so we can create a key representing the field that exist.\n",
    "            2. Listing all of the subkeys that we'd need to take in consideration.\n",
    "            3. Creating an index hash to locate all relavent documents\n",
    "            4. Creation of a list of fields so we can create a schema at that index hash\n",
    "            5. Creation of all subkeys so we can quickly access them by name later\n",
    "            \n",
    "        \"\"\"\n",
    "        for k, v in _requirements.items():\n",
    "            if is_generic(v):\n",
    "                sval = to_str(v)\n",
    "                self._requirements_str[k] = sval\n",
    "                field = to_field(k, sval)\n",
    "                self._indexable.add(to_field(k, sval))\n",
    "                continue\n",
    "                \n",
    "            if v == dict:\n",
    "                self._requirements_str[k] = \"SUB\"\n",
    "                self.subnames.add(k)\n",
    "                continue\n",
    "\n",
    "            if is_geo(v):\n",
    "                self._requirements_str[k] = \"GEO\"\n",
    "                self._indexable.add(to_field(k, \"GEO\"))\n",
    "                continue\n",
    "        self._index_key = consistent_hash(self._requirements_str)\n",
    "        self.process_subfields()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseSearchHandler(BaseSearchHandlerSupport):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._entity = None\n",
    "        # This will only be here as an example\n",
    "        self.requirements = {\n",
    "            \"name\": str,\n",
    "            \"category\": str,\n",
    "            \"subcategories\": dict\n",
    "        }\n",
    "        \n",
    "        # self.insert_builder = InsertBuilder()\n",
    "        # self.query_builder = QueryBuilder()\n",
    "        \n",
    "        # Subs are all of the subfields we would need to search through\n",
    "        self.subs = {}\n",
    "        # Replacement is a set of fields we'd place in place of the ones we query or find by id\n",
    "        self.replacement = {}\n",
    "        \n",
    "    \n",
    "    @property\n",
    "    def entity(self):\n",
    "        if self._entity is None:\n",
    "            raise AttributeError(\"You haven't set entity yet\")\n",
    "        return entity\n",
    "    \n",
    "    @entity.setter\n",
    "    def entity(self, _entity:str):\n",
    "        self._entity = _entity\n",
    "    \n",
    "    @property\n",
    "    def requirements(self):\n",
    "        return self._requirements_str\n",
    "    \n",
    "    @requirements.setter\n",
    "    def requirements(self, _requirements:dict):\n",
    "        \"\"\"If we set it here we'd go through each dict item and create string version of each key\"\"\"\n",
    "        _requirements['entity'] = str\n",
    "        self.process_requirements(_requirements)\n",
    "    \n",
    "    def find(self, alt={}):\n",
    "        \"\"\"Given the items we've set, find all matching items\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def update(self, alt={}):\n",
    "        \"\"\"\n",
    "            # Update\n",
    "            Given the items or ID we've set, partial update every matching document. \n",
    "            If we have the document_ids already, replace those items\n",
    "        \"\"\"\n",
    "#         insertion_dict = {}\n",
    "#         self.processor.update(insertion_dict)\n",
    "    \n",
    "    def insert(self, alt={}):\n",
    "        \"\"\"\n",
    "            # Insert\n",
    "            Given all of the items we've set, add documents\n",
    "        \"\"\"\n",
    "        insertion_dict = {}\n",
    "        \n",
    "        # self.processor.insert(insertion_dict)\n",
    "        pass\n",
    "    \n",
    "    def remove(self, alt={}):\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset all local variables\"\"\"\n",
    "        pass\n",
    "#     def __setitem__(self, key, value):\n",
    "        \n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'TEXT', 'category': 'TEXT', 'subcategories': 'SUB', 'entity': 'TEXT'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_handler = BaseSearchHandler()\n",
    "base_handler.requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subcategories': 'eyJjYXRlZ29yeSI6IlRFWFQiLCJlbnRpdHkiOiJURVhUIiwibmFtZSI6IlRFWFQiLCJzdWJjYXRlZ29yaWVzIjoiU1VCIn0=:subcategories'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_handler.subfields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
