{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Is This Notebook?\n",
    "\n",
    "This notebook an exploration of using [zadd](https://redis.io/commands/zadd) add data into redis without having any duplicates. Instead of querying for data directly to determine if a piece of data has already been added into the database, we'll instead use the zadd command. We'll serialize information in json format then save it at a given timestamp. The save format will look a little bit like the following:\n",
    "\n",
    "```py\n",
    "{\n",
    "    b\"{...relevant data goes here}\": float(timestamp) \n",
    "}\n",
    "```\n",
    "\n",
    "We'll be able to query all timeseries data using that timestamp we set inside of the zadd function. Technically it's called the `score` inside of redis. It's how we order separate keys of information.\n",
    "\n",
    "\n",
    "Generally we'll be querying using the following concepts:\n",
    "\n",
    "* [ZRANGEBYSCORE](https://redis.io/commands/zrangebyscore) - We'll be able to query by timeindex.\n",
    "* [ZREMRANGEBYSCORE](https://redis.io/commands/zremrangebyscore) - We'll be able to remove data by time index. We could use it to remove the first, last, or any section of data if need be.\n",
    "* [ZRANGE](https://redis.io/commands/zrange) - We'll be able to possibly get the last inputed item.\n",
    "\n",
    "\n",
    "\n",
    "Generally the data is added into redis the following way:\n",
    "\n",
    "\n",
    "```py\n",
    "\n",
    "redis = Redis()\n",
    "\n",
    "data = {\"...key\": float(timestamp), \"...key2\": float(timestamp)}\n",
    "\n",
    "redis.zadd(\"event_key\", *data)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import maya\n",
    "import orjson\n",
    "from copy import copy\n",
    "from redis import Redis\n",
    "from typing import List, Set\n",
    "from jamboree.utils.helper import Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "redis = Redis()\n",
    "helper = Helpers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "\n",
    "---\n",
    "Functions we need to officially handle the dictionary/set manipulation. They're heavily used inside of the save and query latest function.\n",
    "\n",
    "\n",
    "### Using Maya to handle `epoch` time\n",
    "\n",
    "`maya` is a heavily simplified time handling library. You might be wondering why we're using it over datetime and time. Well, that's because of all of the amazing features it has compared to the two native libraries. It allows us to have a variance of handling timeseries information.\n",
    "\n",
    "\n",
    "Just have a look at the ways people can use it simply:\n",
    "\n",
    "\n",
    "```py\n",
    ">>> now = maya.now()\n",
    "<MayaDT epoch=1481850660.9>\n",
    "\n",
    ">>> tomorrow = maya.when('tomorrow')\n",
    "<MayaDT epoch=1481919067.23>\n",
    "\n",
    ">>> tomorrow.slang_date()\n",
    "'tomorrow'\n",
    "\n",
    ">>> tomorrow.slang_time()\n",
    "'23 hours from now'\n",
    "\n",
    "# Also: MayaDT.from_iso8601(...)\n",
    ">>> tomorrow.iso8601()\n",
    "'2017-02-10T22:17:01.445418Z'\n",
    "\n",
    "# Also: MayaDT.from_rfc2822(...)\n",
    ">>> tomorrow.rfc2822()\n",
    "'Fri, 10 Feb 2017 22:17:01 GMT'\n",
    "\n",
    "# Also: MayaDT.from_rfc3339(...)\n",
    ">>> tomorrow.rfc3339()\n",
    "'2017-02-10T22:17:01.44Z'\n",
    "\n",
    ">>> tomorrow.datetime()\n",
    "datetime.datetime(2016, 12, 16, 15, 11, 30, 263350, tzinfo=<UTC>)\n",
    "\n",
    "# Automatically parse datetime strings and generate naive datetimes.\n",
    ">>> scraped = '2016-12-16 18:23:45.423992+00:00'\n",
    ">>> maya.parse(scraped).datetime(to_timezone='US/Eastern', naive=True)\n",
    "datetime.datetime(2016, 12, 16, 13, 23, 45, 423992)\n",
    "\n",
    ">>> rand_day = maya.when('2011-02-07', timezone='US/Eastern')\n",
    "<MayaDT epoch=1297036800.0>\n",
    "\n",
    "# Maya speaks Python.\n",
    ">>> m = maya.MayaDT.from_datetime(datetime.utcnow())\n",
    ">>> print(m)\n",
    "Wed, 20 Sep 2017 17:24:32 GMT\n",
    "\n",
    ">>> m = maya.MayaDT.from_struct(time.gmtime())\n",
    ">>> print(m)\n",
    "Wed, 20 Sep 2017 17:24:32 GMT\n",
    "\n",
    ">>> m = maya.MayaDT(time.time())\n",
    ">>> print(m)\n",
    "Wed, 20 Sep 2017 17:24:32 GMT\n",
    "\n",
    ">>> rand_day.day\n",
    "7\n",
    "\n",
    ">>> rand_day.add(days=10).day\n",
    "17\n",
    "\n",
    "# Always.\n",
    ">>> rand_day.timezone\n",
    "UTC\n",
    "\n",
    "# Range of hours in a day:\n",
    ">>> maya.intervals(start=maya.now(), end=maya.now().add(days=1), interval=60*60)\n",
    "<generator object intervals at 0x105ba5820>\n",
    "\n",
    "# snap modifiers\n",
    ">>> dt = maya.when('Mon, 21 Feb 1994 21:21:42 GMT')\n",
    ">>> dt.snap('@d+3h').rfc2822()\n",
    "'Mon, 21 Feb 1994 03:00:00 GMT'\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "As you can see, the maya library can handle a wide array of time manipulation. This is wonderful as we're moving between the different formats of time. Using it we can also make time manipulation more robust over time. \n",
    "\n",
    "Simply adding the text `ten_ago = maya.now().sub(days=10)` allows us to get 10 days prior to the current point in time. We could then take that time data then convert into epoch required to query our data.\n",
    "\n",
    "`ten_ago._epoch` - This allows us to get an `epoch` to the milisecond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time(item:dict, _time:float, rel_abs=\"absolute\"):\n",
    "    \"\"\" Adds time to the dictionaries we query. \"\"\"\n",
    "    if rel_abs == \"absolute\":\n",
    "        item['timestamp'] = _time\n",
    "    else:\n",
    "        item['time'] = _time\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dicts(data, _time, timestamp):\n",
    "    relative = copy(data)\n",
    "    absolute = copy(data)\n",
    "    relative['time'] = _time\n",
    "    absolute['timestamp'] = _time\n",
    "    return {\n",
    "        \"relative\": relative,\n",
    "        \"absolute\": absolute\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_z_to_dict(zset:List[Set], rel_abs=\"absolute\"):\n",
    "    if len(zset) == 0 or abs_rel not in [\"absolute\", \"relative\"]:\n",
    "        return []\n",
    "    \n",
    "    times = [x[1] for x in zset]\n",
    "    dicts = [add_time(orjson.loads(x[0]), times[i], rel_abs) for i, x in enumerate(zset)]\n",
    "    return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictify(azset:List[Set], rzset:List[Set]):\n",
    "    \"\"\"Creates a single dictionary that represents the information we intend to query. \"\"\"\n",
    "    if len(azset) == 0 or len(rzset) == 0:\n",
    "        return {}\n",
    "    adict = {}\n",
    "    for azs in azset:\n",
    "        item, time = azs\n",
    "        if item == b'{\"placeholder\": \"place\"}':\n",
    "            continue\n",
    "        current_item = adict.get(item, {})\n",
    "        current_item['timestamp'] = time\n",
    "        adict[item] = current_item\n",
    "    \n",
    "    # Set the relative time\n",
    "    for rzs in rzset:\n",
    "        item, time = rzs\n",
    "        if item == b'{\"placeholder\": \"place\"}':\n",
    "            continue\n",
    "        current_item = adict.get(item, {})\n",
    "        current_item['time'] = time\n",
    "        adict[item] = current_item\n",
    "    \n",
    "    return adict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_dicts(dictified:dict):\n",
    "    _deserialized = []\n",
    "    for key, value in dictified.items():\n",
    "        _key = orjson.loads(key)\n",
    "        _key['time'] = value.get(\"time\", maya.now()._epoch)\n",
    "        _key['timestamp'] = value.get(\"timestamp\", maya.now()._epoch)\n",
    "        _deserialized.append(_key)\n",
    "    return _deserialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_time(_time:float, _timestamp:float, local_time:float, local_timestamp:float):\n",
    "    current_time = maya.now()._epoch\n",
    "    \n",
    "    \n",
    "    if local_time is not None:\n",
    "        _time = local_time\n",
    "    elif _time is None:\n",
    "        _time = current_time\n",
    "    if local_timestamp is not None:\n",
    "        _timestamp = local_timestamp\n",
    "    elif _timestamp is None:\n",
    "        _timestamp = current_time\n",
    "    \n",
    "    return {\n",
    "        \"time\": _time,\n",
    "        \"timestamp\": _timestamp\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_time_data(data:dict, _time:float=None, _timestamp:float=None):\n",
    "    local_time = data.pop(\"time\", None)\n",
    "    local_timestamp = data.pop(\"timestamp\", None)\n",
    "    timing = check_time(_time, _timestamp, local_time, local_timestamp)\n",
    "    return data, timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Functions\n",
    "\n",
    "* **save** - Save a single record at a specified time. The specified time will have both **relative** and **absolute** time. \n",
    "    - **Relative time** - This is the time specified by the data source. This is like the index inside of a timeseries dataframe. We'll query these times by epoch time.\n",
    "    - **Absolute time** This is the time the record is saved into the database. The general idea here is that you'll be able to get the data in the order we entered it in as well as the actual timing of the data. We save the data in two *zlists* to represent how we want to query the data.\n",
    "* **save_many**\n",
    "    * Exactly the same as above, only with lots of data at once. This will be useful when we want to save lots of data representing a single data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(query, data, _time=None, _timestamp=None):\n",
    "    if not helper.validate_query(query):\n",
    "        return \n",
    "    _hash = helper.generate_hash(query)\n",
    "    \n",
    "    \n",
    "    query.update(data)\n",
    "    \n",
    "    \n",
    "    \n",
    "    data, timing = separate_time_data(query, _time, _timestamp)\n",
    "    \n",
    "    relative_time_key = f\"{_hash}:rlist\"\n",
    "    absolute_time_key = f\"{_hash}:alist\"\n",
    "\n",
    "    \n",
    "    # Generate Data\n",
    "    mono = orjson.dumps(data)\n",
    "    relative_data = {\n",
    "        mono: timing[\"time\"]\n",
    "    }\n",
    "    absolute_data = {\n",
    "        mono: timing[\"timestamp\"]\n",
    "    }    \n",
    "\n",
    "    redis.zadd(relative_time_key, relative_data)\n",
    "    redis.zadd(absolute_time_key, absolute_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Functions\n",
    "\n",
    "Query all of the data according to our parameters. You'll see the conventional query key query up top. You'll see the `abs_rel` parameter inside of query_latest. The general idea here is that you'll be able to query from either the relative or absolute time factor. Try it out.\n",
    "\n",
    "\n",
    "The query functions you'll have to work on are the following:\n",
    "\n",
    "1. `query` - Get all of the records related to a given key.\n",
    "2. `query_latest` - Get the `n` latest records according to our query parameters.\n",
    "3. `query_between` - Query between two epoch times.\n",
    "4. `query_before` - Get everything before an epoch time.\n",
    "5. `query_after` - Get everything after epoch time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(_query):\n",
    "    if not helper.validate_query(_query):\n",
    "        return \n",
    "    _hash = helper.generate_hash(_query)\n",
    "    relative_time_key = f\"{_hash}:rlist\"\n",
    "    absolute_time_key = f\"{_hash}:alist\"\n",
    "    keys = redis.zrange(relative_time_key, 0, -1, withscores=True)\n",
    "    akeys = redis.zrange(absolute_time_key, 0, -1, withscores=True)\n",
    "\n",
    "    dicts = dictify(akeys, keys)\n",
    "    combined = deserialize_dicts(dicts)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_latest(_query, abs_rel=\"absolute\"):\n",
    "    if not helper.validate_query(_query) or abs_rel not in [\"absolute\", \"relative\"]:\n",
    "        return \n",
    "    _hash = helper.generate_hash(_query)\n",
    "    \n",
    "    _current_key = \"\"\n",
    "    if abs_rel == \"absolute\":\n",
    "        _current_key = f\"{_hash}:alist\"\n",
    "    else:\n",
    "        _current_key = f\"{_hash}:rlist\"\n",
    "    \n",
    "    blank_keys = [(b'{\"placeholder\": \"place\"}', 0)]\n",
    "    keys = redis.zrange(_current_key, -1, -1, withscores=True)\n",
    "    dicts = dictify(keys, blank_keys)\n",
    "    combined = deserialize_dicts(dicts)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_latest_many(_query, abs_rel=\"absolute\", limit:int=10):\n",
    "    if not helper.validate_query(_query) or abs_rel not in [\"absolute\", \"relative\"]:\n",
    "        return \n",
    "    _hash = helper.generate_hash(_query)\n",
    "    \n",
    "    _current_key = \"\"\n",
    "    if abs_rel == \"absolute\":\n",
    "        _current_key = f\"{_hash}:alist\"\n",
    "    else:\n",
    "        _current_key = f\"{_hash}:rlist\"\n",
    "    \n",
    "    blank_keys = [(b'{\"placeholder\": \"place\"}', 0)]\n",
    "    keys = redis.zrange(_current_key, -limit, -1, withscores=True)\n",
    "    dicts = []\n",
    "    if abs_rel == \"absolute\":\n",
    "        dicts = dictify(keys, blank_keys)\n",
    "    else:\n",
    "        \n",
    "        dicts = dictify(blank_keys, keys)\n",
    "    \n",
    "    combined = deserialize_dicts(dicts)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode = uuid.uuid1().hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save({\"type\": \"hello\", \"episode\": episode}, {\"name\":\"world\"}, _time=(maya.now()._epoch + 3600))\n",
    "save({\"type\": \"hello\", \"episode\": episode}, {\"name\":\"world\", \"my\": \"world\"}, _time=(maya.now()._epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'hello',\n",
       "  'episode': 'c860beb4398e11ea8afc80c5f21e8205',\n",
       "  'name': 'world',\n",
       "  'time': 1579309600.2006888,\n",
       "  'timestamp': 1579313200.0233085}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_latest({\"type\": \"hello\", \"episode\": episode}, abs_rel=\"relative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'hello',\n",
       "  'episode': 'c860beb4398e11ea8afc80c5f21e8205',\n",
       "  'name': 'world',\n",
       "  'my': 'world',\n",
       "  'time': 1579309600.406403,\n",
       "  'timestamp': 1579309600.0329309}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_latest({\"type\": \"hello\", \"episode\": episode})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'hello',\n",
       "  'episode': 'c860beb4398e11ea8afc80c5f21e8205',\n",
       "  'name': 'world',\n",
       "  'my': 'world',\n",
       "  'time': 1579309600.032902,\n",
       "  'timestamp': 1579309600.5931542},\n",
       " {'type': 'hello',\n",
       "  'episode': 'c860beb4398e11ea8afc80c5f21e8205',\n",
       "  'name': 'world',\n",
       "  'time': 1579313200.0233085,\n",
       "  'timestamp': 1579309600.5931618}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_latest_many({\"type\": \"hello\", \"episode\": episode}, abs_rel=\"relative\", limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_items = [\n",
    "    {\n",
    "        \"data\": {\"name\":\"world\", \"my\": \"world\", \"_id\": uuid.uuid4().hex},\n",
    "        \"timestamp\": maya.now()._epoch\n",
    "    },\n",
    "    {\n",
    "        \"data\": {\"name\":\"world\", \"my\": \"world\", \"_id\": uuid.uuid4().hex},\n",
    "        \"timestamp\": maya.now()._epoch\n",
    "    },\n",
    "    {\n",
    "        \"data\": {\"name\":\"world\", \"my\": \"world\", \"_id\": uuid.uuid4().hex},\n",
    "        \"timestamp\": maya.now()._epoch\n",
    "    },\n",
    "    {\n",
    "        \"data\": {\"name\":\"world\", \"my\": \"world\", \"_id\": uuid.uuid4().hex},\n",
    "        \"timestamp\": maya.now()._epoch\n",
    "    },\n",
    "    {\n",
    "        \"data\": {\"name\":\"world\", \"my\": \"world\", \"_id\": uuid.uuid4().hex},\n",
    "        \"timestamp\": maya.now()._epoch\n",
    "    },\n",
    "    {\n",
    "        \"data\": {\"name\":\"world\", \"my\": \"world\", \"_id\": uuid.uuid4().hex},\n",
    "        \"timestamp\": maya.now()._epoch\n",
    "    },\n",
    "    {\n",
    "        \"data\": {\"name\":\"world\", \"my\": \"world\", \"_id\": uuid.uuid4().hex},\n",
    "        \"timestamp\": maya.now()._epoch\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_storable(items:list):\n",
    "    savable = {}\n",
    "    for item in items:\n",
    "        item_json = orjson.dumps(item.get(\"data\", {}))\n",
    "        timestamp = item.get(\"timestamp\", maya.now()._epoch)\n",
    "        savable[item_json] = timestamp\n",
    "    \n",
    "    return savable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'{\"name\":\"world\",\"my\":\"world\",\"_id\":\"7d2201ad9abe4ea39c9190c4a9044725\"}': 1579309600.792451,\n",
       " b'{\"name\":\"world\",\"my\":\"world\",\"_id\":\"31d268839be2478f94d7ccc772367adb\"}': 1579309600.7924693,\n",
       " b'{\"name\":\"world\",\"my\":\"world\",\"_id\":\"41c09a60a5384e96a0e4034265376f66\"}': 1579309600.7924771,\n",
       " b'{\"name\":\"world\",\"my\":\"world\",\"_id\":\"10cc6583fd2e4173b2505e6a08027efb\"}': 1579309600.7924838,\n",
       " b'{\"name\":\"world\",\"my\":\"world\",\"_id\":\"5263497b957c48c8b6c1bed597c26ae1\"}': 1579309600.7924902,\n",
       " b'{\"name\":\"world\",\"my\":\"world\",\"_id\":\"caa7a3fec10f40a39a258965925d1745\"}': 1579309600.7924974,\n",
       " b'{\"name\":\"world\",\"my\":\"world\",\"_id\":\"7c99f1ce861d451aad53f3ec2521619c\"}': 1579309600.7925045}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_storable(all_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Commands\n",
    "\n",
    "1. `delete` - Get all of the records related to a given key.\n",
    "2. `delete_latest` - Get the `n` latest records according to our query parameters.\n",
    "3. `delete_between` - Query between two epoch times.\n",
    "4. `delete_before` - Get everything before an epoch time.\n",
    "5. `delete_after` - Get everything after epoch time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Head-Based Backtesting\n",
    "---\n",
    "Here you'll be shifting the head forward by a given amount over time. The `head` is an epoch representing where we'll be querying everything from. Combined with either the `query_before` or `query_between` function we can get information on a rolling basis.\n",
    "\n",
    "Your task here will be to create a class that would:\n",
    "\n",
    "1. Define a `head`\n",
    "    * This should be an epoch that is the start of a backtest. We can get the beginning of a data source and get the n seconds/hours/days after.\n",
    "2. Define an `interval` that we'll move the head forward.\n",
    "    * For example, `1 hour` would be 3600 seconds in _epoch time.\n",
    "3. Define a `step` function that would push the head forward by a given interval\n",
    "4. Save the `head` into redis consistently as you update it.\n",
    "5. Apply a distributed lock around the head to ensure that the head isn't overwritten by accident.\n",
    "    * A `redis-py` [lock](https://github.com/andymccurdy/redis-py/blob/master/redis/lock.py) polls a given key and prevents the usage of that key while the key is getting worked on.\n",
    "    \n",
    "\n",
    "```py\n",
    "with lock(redis, \"key_name\"):\n",
    "    \"\"\"Do work here\"\"\"\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
